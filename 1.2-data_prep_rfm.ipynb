{"nbformat":4,"nbformat_minor":5,"metadata":{"notebookId":"981b7666-1d0f-4cc9-ac2d-6eb29db798af","language_info":{"version":"3.7.7","file_extension":".py","pygments_lexer":"ipython3","nbconvert_exporter":"python","name":"python","codemirror_mode":{"version":3,"name":"ipython"},"mimetype":"text/x-python"},"kernelspec":{"name":"python3","display_name":"Yandex DataSphere Kernel","language":"python"}},"cells":[{"cell_type":"markdown","source":"# Подготовка данных для rfm моделей\n\n","metadata":{"cellId":"qegzwuxsodl0dced7cp4sb"}},{"cell_type":"code","source":"%enable_full_walk\nimport sys\nimport numpy as np\nimport pandas as pd\n\nimport os\nimport functools as ft\nroot = ft.reduce(os.path.join, ['..'])\n\nimport pickle\nimport scipy\nfrom scipy.sparse import coo_matrix\n\nfrom sklearn.model_selection import train_test_split\n\ndef load_mapping(filename):\n    map_path = ft.reduce(os.path.join, ['..','data','mapping' ,filename+'.pkl'])\n    with open(map_path, 'rb') as handle:\n        return pickle.load(handle)","metadata":{"cellId":"zwhrw3klawk6mfoowop3","trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"path = ft.reduce(os.path.join, ['..','data', 'raw', 'purchases.csv'])\ndf = pd.read_csv(path, dtype={'transaction_id': 'str',\n                                'product_id': 'str',\n                                'store_id': 'str',\n                                'client_id': 'str'},\n                 usecols=['client_id', 'transaction_id', 'transaction_datetime',\\\n                  'store_id', 'product_id', 'product_quantity', 'trn_sum_from_iss'])\n                 \nclient_id_to_idx = load_mapping('client_id_to_idx')\nproduct_id_to_idx = load_mapping('product_id_to_idx')\ntrans_id_to_idx = load_mapping('trans_id_to_idx')\nstore_id_to_idx = load_mapping('store_id_to_idx')\nproducts_list = list(product_id_to_idx.values())\n\n# Далее работаем с датасетом, где сохраняется только внутренняя индексация\ndf['transaction_idx'] = df.transaction_id.map(trans_id_to_idx)\ndf['product_idx'] = df.product_id.map(product_id_to_idx)\ndf['client_idx'] = df.client_id.map(client_id_to_idx)\ndf['store_idx'] = df.store_id.map(store_id_to_idx)\n\ndf.dropna(subset=['transaction_idx', 'product_idx', 'client_idx', 'store_idx'], inplace=True)\n\ncols = ['transaction_datetime', 'transaction_idx', 'client_idx', 'store_idx', 'product_idx', 'product_quantity', 'trn_sum_from_iss']\ndf = df[cols]\n\n# Сортируем по времени\ndf.sort_values('transaction_datetime', inplace=True)\ndf.reset_index(inplace=True, drop=True)\n\ndf[['transaction_idx', 'product_idx', 'client_idx', 'store_idx']] = df[['transaction_idx', 'product_idx', 'client_idx', 'store_idx']].astype(int)\n","metadata":{"cellId":"pyuadm6z1xbroast2wlazp","trusted":true},"outputs":[],"execution_count":2200},{"cell_type":"code","source":"# Берем последнюю транзакцию каждого клиента\ntransactions = df[['transaction_idx', 'client_idx', 'transaction_datetime', 'store_idx']].drop_duplicates()\nold_trans = transactions.groupby('client_idx').apply(lambda x: x[x.transaction_datetime == x.transaction_datetime.max()])\ndel transactions","metadata":{"cellId":"9zvqdm0huxo70m7yovu9","trusted":true},"outputs":[],"execution_count":2211},{"cell_type":"markdown","source":"# Расчет RFM агрегатов","metadata":{"cellId":"dt6iplpzy9wp9t8knfm5j8"}},{"cell_type":"code","source":"X_train = pd.read_csv(ft.reduce(os.path.join, [root, 'data', 'processed', 'client_hist_context_target_product.csv']), index_col=0)\n# Выбираем только клиентов с историей\nX_train = X_train[~X_train['is_new_client']]\n\nold_trans_ = old_trans[old_trans.client_idx.isin(X_train.index.unique().values)].copy()\n\ndf['transaction_datetime'] = pd.to_datetime(df.transaction_datetime)\nold_trans_['transaction_datetime'] = pd.to_datetime(old_trans_.transaction_datetime)","metadata":{"cellId":"kk3fmaxcwgkvqyrmjsl69g","trusted":true},"outputs":[],"execution_count":2220},{"cell_type":"code","source":"h_columns = ['last_purch_days_' + str(x) for x in range(len(products_list))]\ntime_last_purch = np.full(len(products_list), np.inf)\n\n# Количество дней после покупки товара\ndef get_last_purch_days(x):\n\n    hist = df[(df.client_idx == x.client_idx) & (df.transaction_datetime < x.transaction_datetime)]\n\n    hist = hist[['product_idx', 'transaction_datetime']]\n    hist.drop_duplicates(keep='last', inplace=True)\n    hist['cur_tdt'] = x.transaction_datetime\n    hist.set_index('product_idx', inplace=True)\n    hist['time_last_purch'] = (hist['cur_tdt'] - hist['transaction_datetime']).apply(lambda x: x.days)\n    time_last_purch_ = time_last_purch.copy()\n    time_last_purch_[hist.index.values] = hist['time_last_purch'].values\n   \n    return pd.Series(time_last_purch_, index=h_columns)\n\nold_trans_last_purch = old_trans_.apply(get_last_purch_days, axis=1)","metadata":{"cellId":"ybkyuvz8vynfbapt9uelii","trusted":true},"outputs":[],"execution_count":2222},{"cell_type":"code","source":"h_columns = ['h_' + str(x) for x in range(len(products_list))]\nzeros_hist = np.zeros(len(products_list)).astype(int)\n\n# Количество покупок товара в истории\ndef get_history_products(x):\n\n    hist = df[(df.client_idx == x.client_idx) & (df.transaction_datetime < x.transaction_datetime)]\n\n    vc = hist.product_idx.value_counts()\n\n    exp_hist = zeros_hist.copy()\n    exp_hist[vc.index.values] = vc.values\n\n    return pd.Series(exp_hist, index=h_columns)\n\nold_trans_frequency = old_trans_.apply(get_history_products, axis=1)\nold_trans_frequency.columns = ['hist_prod_freq_' + str(x) for x in range(len(products_list))]\nold_trans_frequency = old_trans_frequency.div(old_trans_frequency.sum(axis=1), axis=0)","metadata":{"cellId":"z9vac8ir5n3rrs9ajdceh","trusted":true},"outputs":[],"execution_count":2223},{"cell_type":"code","source":"h_columns = ['hist_purch_sum_' + str(x) for x in range(len(products_list))]\nzeros_sum = np.zeros(len(products_list))\n\n#Относительные траты на товар\ndef get_purch_sum(x):\n\n    hist = df[(df.client_idx == x.client_idx) & (df.transaction_datetime < x.transaction_datetime)]\n\n    hist = hist[['product_idx', 'trn_sum_from_iss']]\n    hist = hist.groupby('product_idx').sum()\n    \n    zeros_sum_ = zeros_sum.copy()\n    zeros_sum_[hist.index.values] = hist['trn_sum_from_iss'].values\n   \n    return pd.Series(zeros_sum_, index=h_columns)\n\nold_trans_purch_summ = old_trans_.apply(get_purch_sum, axis=1)\nold_trans_purch_relative_summ = old_trans_purch_summ.div(old_trans_purch_summ.sum(axis=1), axis=0)","metadata":{"cellId":"nu7tp7wucggyhlzubk1yh","trusted":true},"outputs":[],"execution_count":2224},{"cell_type":"code","source":"h_columns = ['hist_purch_period_sum_' + str(x) for x in range(len(products_list))]\nzeros_sum = np.zeros(len(products_list))\n\n# Сумма трат на товар за год\ndef get_purch_period_sum(x):\n\n    hist = df[(df.client_idx == x.client_idx) & (df.transaction_datetime < x.transaction_datetime)].copy()\n    \n    hist['diff_days'] = hist.apply(lambda y: (x.transaction_datetime - y.transaction_datetime).days, axis=1)\n    hist = hist[hist['diff_days'] < 366]\n\n    hist = hist[['product_idx', 'trn_sum_from_iss']]\n    hist = hist.groupby('product_idx').sum()\n    \n    zeros_sum_ = zeros_sum.copy()\n    zeros_sum_[hist.index.values] = hist['trn_sum_from_iss'].values\n   \n    return pd.Series(zeros_sum_, index=h_columns)\n\nold_trans_purch_period_summ = old_trans_.apply(get_purch_period_sum, axis=1)","metadata":{"cellId":"ldwmlnnu6nn4hbzfo10rhm","trusted":true},"outputs":[],"execution_count":2225},{"cell_type":"code","source":"rfm = pd.concat([old_trans_purch_period_summ, old_trans_last_purch, old_trans_frequency, old_trans_purch_relative_summ], axis=1)\nrfm = rfm.droplevel(1)\nX_train_ = X_train.join(rfm, how='left')\nX_train_.to_csv(ft.reduce(os.path.join, ['..','data', 'processed', 'rfm_client_hist_context_target_product.csv']), index=True)","metadata":{"cellId":"x7jm2xlortpqeryjf2vt4g","trusted":true},"outputs":[],"execution_count":2233}]}
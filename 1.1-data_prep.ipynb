{"nbformat":4,"nbformat_minor":5,"metadata":{"notebookId":"7b5cc803-3b64-4b98-933c-511cd3f99025","language_info":{"version":"3.7.7","file_extension":".py","pygments_lexer":"ipython3","nbconvert_exporter":"python","name":"python","codemirror_mode":{"version":3,"name":"ipython"},"mimetype":"text/x-python"},"kernelspec":{"name":"python3","display_name":"Yandex DataSphere Kernel","language":"python"}},"cells":[{"cell_type":"markdown","source":"# Подготовка данных\n\n","metadata":{"cellId":"qegzwuxsodl0dced7cp4sb"}},{"cell_type":"code","source":"%enable_full_walk\nimport sys\nimport numpy as np\nimport pandas as pd\n\nimport os\nimport functools as ft\nroot = ft.reduce(os.path.join, ['..'])\n\nsys.path.append(root)\n\nimport pickle\nimport scipy\nfrom scipy.sparse import coo_matrix\n\nfrom sklearn.model_selection import train_test_split\n\ndef load_mapping(filename):\n    map_path = ft.reduce(os.path.join, ['..','data','mapping' ,filename+'.pkl'])\n    with open(map_path, 'rb') as handle:\n        return pickle.load(handle)","metadata":{"cellId":"zwhrw3klawk6mfoowop3","trusted":true},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"### Загрузка данных","metadata":{"cellId":"hz0q4hns9ipac53m46zr9i"}},{"cell_type":"code","source":"path = ft.reduce(os.path.join, ['..','data', 'raw', 'purchases.csv'])\ndf = pd.read_csv(path, dtype={'transaction_id': 'str',\n                                'product_id': 'str',\n                                'store_id': 'str',\n                                'client_id': 'str'}, #nrows=10, \n                 usecols=['client_id', 'transaction_id', 'transaction_datetime', 'store_id', 'product_id'])\n\ndf = df[df['product_id'].isin(df['product_id'].value_counts()[:200].index.tolist())]\n\n# Убираем коллизии в индексах транзакций\ntransactions = df[['transaction_id', 'transaction_datetime', 'store_id']].drop_duplicates()\ntrans_without_collision = transactions.groupby('transaction_id').count()['transaction_datetime']\ntrans_without_collision = trans_without_collision[trans_without_collision == 1].index.values\ndel transactions\n\ndf = df[df.transaction_id.isin(trans_without_collision)]\ndel trans_without_collision\n\n# Убираем корзины с малым количеством товаров\nv_c = df['transaction_id'].value_counts() \nv_c = v_c[v_c > 2]\ndf = df[df.transaction_id.isin(v_c.index.values)]\ndel v_c\n\n# Сортируем по времени\ndf.sort_values('transaction_datetime', inplace=True)\ndf.reset_index(inplace=True, drop=True)\n","metadata":{"cellId":"cbdhzpscs9qdvldswnh8dp","trusted":true},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"### Создание словарей с внутренней индексацией","metadata":{"cellId":"qz7oi2u9obbfky02zquna6"}},{"cell_type":"code","source":"# Клиент\nclient_idx_to_id = dict(enumerate(df.client_id.unique()))\nclient_id_to_idx = {v: k for k, v in client_idx_to_id.items()}\n# Продукт\nproduct_idx_to_id = dict(enumerate(df.product_id.unique()))\nproduct_id_to_idx = {v: k for k, v in product_idx_to_id.items()}\n# Магазин\nstore_idx_to_id = dict(enumerate(df.store_id.unique()))\nstore_id_to_idx = {v: k for k, v in store_idx_to_id.items()}\n# Транзакции\ntrans_idx_to_id = dict(enumerate(df.transaction_id.unique()))\ntrans_id_to_idx = {v: k for k, v in trans_idx_to_id.items()}","metadata":{"cellId":"pnlgrj3j8dpbdyf7gfueyu","trusted":true},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def save_mapping(structure, filename):\n    map_path = ft.reduce(os.path.join, ['..','data','mapping' ,filename+'.pkl'])\n    with open(map_path, 'wb') as handle:\n        pickle.dump(structure, handle, protocol=pickle.HIGHEST_PROTOCOL)\n    \nsave_mapping(client_idx_to_id, 'client_idx_to_id')\nsave_mapping(client_id_to_idx, 'client_id_to_idx')\n\nsave_mapping(product_idx_to_id, 'product_idx_to_id')\nsave_mapping(product_id_to_idx, 'product_id_to_idx')\n\nsave_mapping(store_idx_to_id, 'store_idx_to_id')\nsave_mapping(store_id_to_idx, 'store_id_to_idx')\n\nsave_mapping(trans_idx_to_id, 'trans_idx_to_id')\nsave_mapping(trans_id_to_idx, 'trans_id_to_idx')\n","metadata":{"cellId":"yfb1azbrsmc5i3n1bxjrol","trusted":true},"outputs":[],"execution_count":29},{"cell_type":"code","source":"# Далее работаем с датасетом, где сохраняется только внутренняя индексация\ndf['transaction_idx'] = df.transaction_id.map(trans_id_to_idx).astype(int)\ndf['product_idx'] = df.product_id.map(product_id_to_idx).astype(int)\ndf['client_idx'] = df.client_id.map(client_id_to_idx).astype(int)\ndf['store_idx'] = df.store_id.map(store_id_to_idx).astype(int)\n\ncols = ['transaction_datetime', 'transaction_idx', 'client_idx', 'store_idx', 'product_idx']\n\ndf = df[cols]\ndf.to_csv(ft.reduce(os.path.join, ['..', 'data', 'processed', 'purchases.csv']), index=False)","metadata":{"cellId":"omo1cp7r0ainj668nhw2","trusted":true},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"### Сбор контекста корзин","metadata":{"cellId":"engoevhwt5bpp27ny7cxa"}},{"cell_type":"code","source":"df = pd.read_csv(ft.reduce(os.path.join, ['..','data', 'processed', 'purchases.csv']), \n                 dtype={'transaction_idx': 'int',\n                        'product_idx': 'int',\n                        'store_idx': 'int',\n                        'client_idx': 'int'})","metadata":{"cellId":"qnzuluackhojf33lulwfh","trusted":true},"outputs":[],"execution_count":669},{"cell_type":"code","source":"# Берем уникальные транзакции\ntransactions = df[['transaction_idx', 'transaction_datetime', 'store_idx']].drop_duplicates()\ntransactions.set_index('transaction_idx', inplace=True)\n\n\n# Для каждой корзины сохраняем количество товаров\ntransactions['product_count'] = df['transaction_idx'].value_counts()\n\n# Генерируем временной контекст\ntransactions.transaction_datetime = transactions.transaction_datetime.apply(lambda x: pd.to_datetime(x))\ntransactions['hour'] = transactions.transaction_datetime.apply(lambda x: x.hour)\ntransactions['dayofweek'] = transactions.transaction_datetime.apply(lambda x: x.dayofweek)\ntransactions['day'] = transactions.transaction_datetime.apply(lambda x: x.day)\ntransactions['month'] = transactions.transaction_datetime.apply(lambda x: x.month)\ntransactions['year'] = transactions.transaction_datetime.apply(lambda x: x.year)","metadata":{"cellId":"6k2rhl3a9mjsin6ysr2x","trusted":true},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# Сохранение контекста корзин\ntrans_context_columns = ['store_idx', 'product_count', 'hour', 'dayofweek', 'day', 'month', 'year']\ntransactions = transactions[trans_context_columns]\n\ntransactions.to_csv(ft.reduce(os.path.join, ['..', 'data', 'interim', 'trans_context.csv']), index=True)","metadata":{"cellId":"q7dyebj9ela3of5p3pi1","trusted":true},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"### Сбор профиля клиента\nКлиент представлен в виде конкатенации двух векторов - истории покупок и текущей корзины.\n\nИстория покупок для неидентифицированных клиентов - нулевой вектор.","metadata":{"cellId":"zewt86i9rjxrwnd4jq3r"}},{"cell_type":"code","source":"# Загрузка данных\ndf = pd.read_csv(ft.reduce(os.path.join, ['..','data', 'processed', 'purchases.csv']), \n                 dtype={'transaction_idx': 'int',\n                        'product_idx': 'int',\n                        'store_idx': 'int',\n                        'client_idx': 'int'})\n\ntransactions = pd.read_csv(ft.reduce(os.path.join, ['..', 'data', 'interim', 'trans_context.csv']))\ntransactions.set_index('transaction_idx', inplace=True)\n\nproduct_id_to_idx = load_mapping('product_id_to_idx')","metadata":{"cellId":"ut1qlglvbf9m02z4psmc4","trusted":true},"outputs":[],"execution_count":694},{"cell_type":"code","source":"# Последнюю транзакцию клиента будем использовать, как текущую корзину\nclient_basket = df.groupby('client_idx').apply(lambda x: x[x.transaction_datetime == x.transaction_datetime.max()])\nclient_history = df.groupby('client_idx').apply(lambda x: x[x.transaction_datetime != x.transaction_datetime.max()])\n\nclient_basket.reset_index(drop=True, inplace=True)\nclient_history.reset_index(drop=True, inplace=True)\n\nproducts_list = list(product_id_to_idx.values())\n\ndef get_negative_sample(products_list, basket):\n    \"\"\"Получение негативного таргета для корзины клиента. \n    Негативный таргет - случайный товар из католога за исключением товаров в корзине.\"\"\"\n    \n    neg_samples = list(set(products_list)-set(basket))  \n    return np.random.choice(neg_samples, 1)[0]\n\n# Создание отрицательного таргета для каждого клиента\nneg_target = client_basket.groupby('client_idx').product_idx\\\n    .apply(lambda x: get_negative_sample(products_list, x.values))\n\n# Выберем случайный товар для положительного таргета из корзины\ntarget = client_basket.groupby('client_idx').product_idx.apply(lambda x: x.sample(n=1).values[0])\ntarget = target.reset_index()\n\n# Убираем таргет из корзины\nwithout_target = pd.concat([client_basket[['client_idx', 'product_idx']], target, target]).drop_duplicates(keep=False)\n\n# Не учитываем количество товаров в истории\nclient_history = client_history[['client_idx', 'product_idx']].drop_duplicates() ","metadata":{"cellId":"ts3zxm6k12zutorppma29","trusted":true},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# Делаем матричное представление для пар клиент-товар_в_истории\nclient_history['value'] = [True]*client_history.shape[0]\nclient_history = client_history.pivot(index='client_idx', columns='product_idx')['value'].fillna(False).add_prefix('h_')\n\n# Делаем матричное представление для пар клиент-товар_в_корзине\nwithout_target['value'] = [True]*without_target.shape[0]\nwithout_target = without_target.pivot(index='client_idx', columns='product_idx')['value'].fillna(False).add_prefix('b_')\n\n# Последние транзакции клиентов - текущая корзина\nbasket_transactions = client_basket[['client_idx', 'transaction_idx']].drop_duplicates()\nbasket_transactions = basket_transactions.set_index('client_idx', drop=True)","metadata":{"cellId":"lv0kbod6rblcyai3l99oyv","trusted":true},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"Зануляем историю для определенного % клиентов","metadata":{"cellId":"x6tg7ao7a1mblkrh0uut"}},{"cell_type":"code","source":"# Реальные клиенты с только одной транзакцией\nall_clients = df[['client_idx', 'transaction_idx']].drop_duplicates().groupby('client_idx').count()\nnew_clients = all_clients[all_clients < 2].dropna().index.values\nold_clients = all_clients[all_clients > 1].dropna().index.values\n\nratio = 0.9\nn = int(all_clients.shape[0]*ratio - len(new_clients)) # Кол-во клиентов для зануления истории\n\n# Отбор кандидатов для зануления\ncandidates = np.random.choice(old_clients, n, replace=False)\nclient_history.loc[candidates] = False","metadata":{"cellId":"0jlsd1a9vkdwp9el45f7as","trusted":true},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# Контекст текущей корзины клиента\nclient_context = transactions.loc[basket_transactions.transaction_idx.values].set_index(basket_transactions.index)\n\n# Сборка датасета с историей, текущей корзиной и контекстом покупки\nclient_full_df = client_history.join(without_target , how='right').fillna(False)\nclient_full_df = client_full_df.join(client_context)\n\n# Флаг на нового клиента\nclient_full_df['is_new_client'] = ~client_full_df.loc[:, 'h_0':'h_199'].any(axis=1)\n\n# Положительный таргет для клиентов\nclient_full_df_pos = client_full_df.copy()\nclient_full_df_pos['target_product'] = target.product_idx\nclient_full_df_pos['target'] = 1\n\n# Отрицательный таргет для клиентов\nclient_full_df_neg = client_full_df.copy()\nclient_full_df_neg['target_product'] = neg_target\nclient_full_df_neg['target'] = 0\n\n# Объединение + и - таргета в один датасет\nclient_full_df = pd.concat([client_full_df_pos, client_full_df_neg])\ndel client_full_df_neg, client_full_df_pos\n\n# Сортировка клиентов по дате текущей корзины\nclient_full_df = client_full_df.sort_values(['year', 'month', 'day', 'hour', 'client_idx', 'target'])\n\n# Запись\nclient_full_df.to_csv(ft.reduce(os.path.join, ['..', 'data', 'interim', 'client_hist_context_target.csv']), index=True)","metadata":{"cellId":"0msw8je5ganaz9592zzm8o","trusted":true},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"#### Добавление атрибутов клиентов","metadata":{"cellId":"2wdgr8bv0v4tw91jnk9qvi"}},{"cell_type":"code","source":"client_full_df = pd.read_csv(ft.reduce(os.path.join, ['..', 'data', 'interim', 'client_hist_context_target.csv']))\nclient_full_df.set_index('client_idx', inplace=True)\n\nclients = pd.read_csv(ft.reduce(os.path.join, ['..', 'data', 'raw', 'clients.csv']))\n\nclient_id_to_idx = load_mapping('client_id_to_idx')","metadata":{"cellId":"58yirdgw00t0fj3rjch3mba","trusted":true},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# Работа с клиентским датасетом. Приведение индексов к внутреннему стандарту. \nclients['client_idx'] = clients.client_id.map(client_id_to_idx)\nclients.dropna(inplace=True)\nclients['client_idx'] = clients['client_idx'].astype(int)\nclients.set_index('client_idx', inplace=True)\n\n# Заполнение выбросов модой\nmode = clients.age.mode()[0]\nclients.age = clients.age.apply(lambda x: mode if x < 10 or x > 80 else x)\n\nclients = clients[['age', 'gender']]\n\nclients.to_csv(ft.reduce(os.path.join, ['..', 'data', 'processed', 'clients.csv']), index=True)","metadata":{"cellId":"utn9l4qgj0b01fbdhewyaly","trusted":true},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# Добавление доп информации о клиентах в основной датасет\nclient_full_df['age'] = clients['age']\nclient_full_df['gender'] = clients['gender']\n\nclient_full_df.gender.fillna('U', inplace=True)\nclient_full_df.age.fillna(mode, inplace=True)","metadata":{"cellId":"nybujr5duzjfre6r21won","trusted":true},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":"#### Добавление атрибутов товара из таргета","metadata":{"cellId":"ym1xhamca2igfa2p9dswc"}},{"cell_type":"code","source":"# Загрузка данных о товарах и приведение индексов\nproducts = pd.read_csv(ft.reduce(os.path.join, ['..', 'data', 'raw', 'products.csv']))\n#product_id_to_idx = load_mapping('product_id_to_idx')\nproducts['product_idx'] = products.product_id.astype('str').map(product_id_to_idx)\n\nproducts.dropna(subset=['product_idx'], inplace=True)\nproducts['product_idx'] = products['product_idx'].astype(int)\n\n# Заполнение пропусков для категориальных признаков и label encoding\nfor column in ['level_1', 'level_2', 'level_3', 'level_4', 'segment_id', 'brand_id', 'vendor_id']:\n    products[column].fillna('null', inplace=True)\n    products[column] = products[column].astype('category').cat.codes\n    \nproducts.set_index('product_idx', inplace=True)\nproducts = products[['level_1', 'level_2', 'level_3', 'level_4', 'segment_id', 'brand_id', 'vendor_id', 'is_own_trademark']]\nproducts = products.add_prefix('prdt_')\n\n# Запись информации о товарах\nproducts.to_csv(ft.reduce(os.path.join, ['..', 'data', 'processed', 'products.csv']), index=True)","metadata":{"cellId":"512wu60xjd9c9x6m9fm8e4","trusted":true},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# Добавление доп информации о продуктах из таргета в основной датасет\nclient_full_df = client_full_df.join(products, on='target_product', how='left')\n\n# label encoding\n# 0-F, 1-M, 2-U\nclient_full_df['gender'] = client_full_df['gender'].astype('category').cat.codes\n\n# Запись датасета для обучения и тестирования\nclient_full_df.to_csv(ft.reduce(os.path.join, ['..', 'data', 'processed', 'client_hist_context_target_product.csv']), index=True)","metadata":{"cellId":"7qoyspbb0hq5ydeujv499k","trusted":true},"outputs":[],"execution_count":30},{"cell_type":"code","source":"","metadata":{"cellId":"rctg0grwkrep5fdi3u2ur"},"outputs":[],"execution_count":null}]}